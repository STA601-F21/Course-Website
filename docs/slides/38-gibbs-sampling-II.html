<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>STA 360/602L: Module 3.8</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dr. Olanrewaju Michael Akande" />
    <link href="libs/font-awesome/css/all.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <link rel="stylesheet" href="slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# STA 360/602L: Module 3.8
## MCMC and Gibbs sampling II
### Dr. Olanrewaju Michael Akande

---








## Example: bivariate normal

- Consider
.block[
.small[
`\begin{eqnarray*}
\begin{pmatrix}\theta_1\\
\theta_2
\end{pmatrix} &amp; \sim &amp; \mathcal{N}\left[\left(\begin{array}{c}
0\\
0
\end{array}\right),\left(\begin{array}{cc}
1 &amp; \rho \\
\rho &amp; 1 
\end{array}\right)\right]\\
\end{eqnarray*}`
]
]

  where `\(\rho\)` is known (and is the correlation between `\(\theta_1\)` and `\(\theta_2\)`).

--

- We will review details of the multivariate normal distribution very soon but for now, let's use this example to explore Gibbs sampling.

--

- For this density, turns out that we have
.block[
.small[
`$$\theta_1|\theta_2 \sim \mathcal{N}\left(\rho\theta_2, 1-\rho^2 \right)$$`
]
]

  and
.block[
.small[
`$$\theta_2|\theta_1 \sim \mathcal{N}\left(\rho\theta_1, 1-\rho^2 \right)$$`
]
]

--

- While we can easily sample directly from this distribution (using the `mvtnorm` or `MASS` packages in R), let's instead use the Gibbs sampler to draw samples from it.



---
## Bivariate normal

First, a few examples of the bivariate normal distribution.
.midsmall[
`\begin{eqnarray*}
\begin{pmatrix}\theta_1\\
\theta_2
\end{pmatrix} &amp; \sim &amp; \mathcal{N}\left[\left(\begin{array}{c}
0\\
0
\end{array}\right),\left(\begin{array}{cc}
1 &amp; 0 \\
0 &amp; 1 
\end{array}\right)\right]\\
\end{eqnarray*}`
]

&lt;img src="38-gibbs-sampling-II_files/figure-html/unnamed-chunk-2-1.png" style="display: block; margin: auto;" /&gt;



---
## Bivariate normal

.midsmall[
`\begin{eqnarray*}
\begin{pmatrix}\theta_1\\
\theta_2
\end{pmatrix} &amp; \sim &amp; \mathcal{N}\left[\left(\begin{array}{c}
0\\
0
\end{array}\right),\left(\begin{array}{cc}
1 &amp; 0 \\
0 &amp; 1 
\end{array}\right)\right]\\
\end{eqnarray*}`
]

&lt;img src="38-gibbs-sampling-II_files/figure-html/unnamed-chunk-3-1.png" style="display: block; margin: auto;" /&gt;




---
## Bivariate normal

.midsmall[
`\begin{eqnarray*}
\begin{pmatrix}\theta_1\\
\theta_2
\end{pmatrix} &amp; \sim &amp; \mathcal{N}\left[\left(\begin{array}{c}
0\\
2
\end{array}\right),\left(\begin{array}{cc}
1 &amp; 0.5 \\
0.5 &amp; 2 
\end{array}\right)\right]\\
\end{eqnarray*}`
]

&lt;img src="38-gibbs-sampling-II_files/figure-html/unnamed-chunk-4-1.png" style="display: block; margin: auto;" /&gt;



---
## Bivariate normal

.midsmall[
`\begin{eqnarray*}
\begin{pmatrix}\theta_1\\
\theta_2
\end{pmatrix} &amp; \sim &amp; \mathcal{N}\left[\left(\begin{array}{c}
0\\
2
\end{array}\right),\left(\begin{array}{cc}
1 &amp; 0.5 \\
0.5 &amp; 2 
\end{array}\right)\right]\\
\end{eqnarray*}`
]

&lt;img src="38-gibbs-sampling-II_files/figure-html/unnamed-chunk-5-1.png" style="display: block; margin: auto;" /&gt;



---
## Bivariate normal

.midsmall[
`\begin{eqnarray*}
\begin{pmatrix}\theta_1\\
\theta_2
\end{pmatrix} &amp; \sim &amp; \mathcal{N}\left[\left(\begin{array}{c}
1\\
-1
\end{array}\right),\left(\begin{array}{cc}
1 &amp; 0.9 \\
0.9 &amp; 1.5 
\end{array}\right)\right]\\
\end{eqnarray*}`
]

&lt;img src="38-gibbs-sampling-II_files/figure-html/unnamed-chunk-6-1.png" style="display: block; margin: auto;" /&gt;



---
## Bivariate normal

.midsmall[
`\begin{eqnarray*}
\begin{pmatrix}\theta_1\\
\theta_2
\end{pmatrix} &amp; \sim &amp; \mathcal{N}\left[\left(\begin{array}{c}
1\\
-1
\end{array}\right),\left(\begin{array}{cc}
1 &amp; 0.9 \\
0.9 &amp; 1.5 
\end{array}\right)\right]\\
\end{eqnarray*}`
]

&lt;img src="38-gibbs-sampling-II_files/figure-html/unnamed-chunk-7-1.png" style="display: block; margin: auto;" /&gt;







---
## Back to the example

- Again, we have
.block[
.small[
`$$\theta_1|\theta_2 \sim \mathcal{N}\left(\rho\theta_2, 1-\rho^2 \right); \ \ \ \ \theta_2|\theta_1 \sim \mathcal{N}\left(\rho\theta_1, 1-\rho^2 \right)$$`
]
]

- Here's a code to do Gibbs sampling using those full conditionals:
  
  ```r
  rho &lt;- #set correlation
  S &lt;- #set number of MCMC samples
  thetamat &lt;- matrix(0,nrow=S,ncol=2)
  theta &lt;- c(10,10) #initialize values of theta
  for (s in 1:S) {
  theta[1] &lt;- rnorm(1,rho*theta[2],sqrt(1-rho^2)) #sample theta1
  theta[2] &lt;- rnorm(1,rho*theta[1],sqrt(1-rho^2)) #sample theta2
  thetamat[s,] &lt;- theta
  }
  ```


- Here's a code to do sample directly instead:
  
  ```r
  library(mvtnorm)
  rho &lt;- #set correlation; no need to set again once you've used previous code
  S &lt;- #set number of MCMC samples; no need to set again once you've used previous code
  Mu &lt;- c(0,0)
  Sigma &lt;- matrix(c(1,rho,rho,1),ncol=2)
  thetamat_direct &lt;- rmvnorm(S, mean = Mu,sigma = Sigma)
  ```



&lt;!-- --- --&gt;
&lt;!-- ## Participation exercise --&gt;

&lt;!-- - You will work in groups of three. Work with the three students closest to you. --&gt;

&lt;!-- - For `\(S \in \{50,250,500\}\)` and `\(\rho \in \{0.1,0.5,0.95\}\)`, do the following: --&gt;
&lt;!--   1. Generate `\(S\)` samples using the two methods. --&gt;
&lt;!--   2. Make a scatter plot of the samples from each method (plot the samples from the Gibbs sampler first) and compare them. --&gt;
&lt;!--   &lt;!-- 3. Overlay the samples from the Gibbs sampler alone on the true bivariate density. **See code on next slide!** --&gt; --&gt;

&lt;!-- - How do the results differ between the two methods for the different combinations of `\(S\)` and `\(\rho\)`? --&gt;

&lt;!-- - Discuss within your teams, document your team findings and submit. --&gt;

&lt;!-- - You can have one person document the findings but make sure to write the name of all three members at the top of the sheet. --&gt;



---
## More code

See how the chain actually evolves with an overlay on the true density:

```r
rho &lt;- #set correlation
Sigma &lt;- matrix(c(1,rho,rho,1),ncol=2); Mu &lt;- c(0,0)
x.points &lt;- seq(-3,3,length.out=100)
y.points &lt;- x.points
z &lt;- matrix(0,nrow=100,ncol=100)
for (i in 1:100) {
  for (j in 1:100) {
    z[i,j] &lt;- dmvnorm(c(x.points[i],y.points[j]),mean=Mu,sigma=Sigma)
  } 
}
contour(x.points,y.points,z,xlim=c(-3,10),ylim=c(-3,10),col="orange2",
        xlab=expression(theta[1]),ylab=expression(theta[2]))

S &lt;- #set number of MCMC samples;
thetamat &lt;- matrix(0,nrow=S,ncol=2)
theta &lt;- c(10,10)
points(x=theta[1],y=theta[2],col="black",pch=2)
for (s in 1:S) {
  theta[1] &lt;- rnorm(1,rho*theta[2],sqrt(1-rho^2))
  theta[2] &lt;- rnorm(1,rho*theta[1],sqrt(1-rho^2))
  thetamat[s,] &lt;- theta
  if(s &lt; 20){
    points(x=theta[1],y=theta[2],col="red4",pch=16); Sys.sleep(1)
  } else {
    points(x=theta[1],y=theta[2],col="green4",pch=16); Sys.sleep(0.1)
  }
}
```



---
## MCMC

- Gibbs sampling is one of several flavors of .hlight[Markov chain Monte Carlo (MCMC)].

--
  + .hlight[Markov chain]: a stochastic process in which future states are independent of past states conditional on the present state.
  
  + .hlight[Monte Carlo]: simulation.

--

- MCMC provides an approach for generating samples from posterior distributions.

--

- From these samples, we can obtain summaries (including summaries of functions) of the posterior distribution for `\(\theta\)`, our parameter of interest.



---
## How does MCMC work?

- Let `\(\theta^{(s)} = (\theta_1^{(s)}, \ldots, \theta_p^{(s)})\)` denote the value of the `\(p \times 1\)` vector of parameters at iteration `\(s\)`.

--

- Let `\(\theta^{(0)}\)` be an initial value used to start the chain (_should not be sensitive_).

--

- MCMC generates `\(\theta^{(s)}\)` from a distribution that depends on the data and potentially on `\(\theta^{(s-1)}\)`, but not on `\(\theta^{(1)}, \ldots, \theta^{(s-2)}\)`.

--

- This results in a Markov chain with **stationary distribution** `\(\pi(\theta | Y)\)` under some conditions on the sampling distribution.

--

- The theory of Markov Chains (structure, convergence, reversibility, detailed balance, stationarity, etc) is well beyond the scope of this course so we will not dive into it. 

--

- If you are interested, consider taking courses on stochastic process.


---
## Properties

- **Note**: Our Markov chain is a collection of draws of `\(\theta\)` that are (slightly we hope!) dependent on the previous draw. 

--

- The chain will wander around our parameter space, only remembering where it had been in the last draw.

--

- We want to have our MCMC sample size, `\(S\)`, big enough so that we can

  + Move out of areas of low probability into regions of high probability (convergence)
  
  + Move between high probability regions (good mixing)
  
  + Know our Markov chain is stationary in time (the distribution of samples is the same for all samples, regardless of location in the chain)

--

- At the start of the sampling, the samples are **not** from the posterior distribution. It is necessary to discard the initial samples as a .hlight[burn-in] to allow convergence. We'll talk more about that in the next class.



---
## Different flavors of MCMC

- The most commonly used MCMC algorithms are:
  + Metropolis sampling (Metropolis et al., 1953).
  + Metropolis-Hastings (MH) (Hastings, 1970).
  + Gibbs sampling (Geman &amp; Geman, 1984; Gelfand &amp; Smith, 1990).
  
- Overview of Gibbs - Casella &amp; George (1992, The American Statistician, 46, 167-174).

--
the first two 
- Overview of MH - Chib &amp; Greenberg (1995, The American Statistician).

--

- We will get to Metropolis and Metropolis-Hastings later in the course.



---

class: center, middle

# What's next? 

### Move on to the readings for the next module!
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
